{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a9e67f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, KBinsDiscretizer, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, HuberRegressor, BayesianRidge, ARDRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, ClassifierMixin, clone\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from src.feature_engineering import *\n",
    "from src.modeling import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf829ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "DATA_PATH = \"data/\"\n",
    "OUTPUT_PATH = \"output/\"\n",
    "BLUEPRINT_PATH = \"output/blueprint/\"\n",
    "MODEL_PATH = \"models/\"\n",
    "\n",
    "BEST_MODELS_LIST = [\n",
    "    \"robust_lgbm_adil_params\",\n",
    "    \"outlier_bayesian_alpha_1_1e_06_alpha_2_0_01_lambda_1_0_01_lambda_2_0_01\",\n",
    "    # \"bayesian_alpha_1_1e_-06_alpha_2_0_01_lambda_1_0_01_lambda_2_0_01\",\n",
    "    \"outlier_lasso_alpha_0_1_max_iter_1000\",\n",
    "    \"outlier_elastic_net_alpha_1_0_l1_ratio_0_1\",\n",
    "    # \"binning_pca_rf_n_bins_5_max_depth_10_min_samples_leaf_2_min_samples_split_2_n_estimator_200_n_components_0_99\",\n",
    "    # \"outlier_pca_ridge_alpha_0_001_solver_auto_n_components_0_85\",\n",
    "    # \"outlier_pca_ard_alpha_1e_-06_alpha_2_1e_-06_lambda_1_0_01_lambda_2_0_01_threshold_lambda_1000_n_components_0_9\",\n",
    "    \"outlier_pca_xgb_lr_0_01_max_depth_3_n_estimators_100_n_components_0_85\",\n",
    "    # \"robust_catboost_adil_params\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36869b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(524164, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>RhythmScore</th>\n",
       "      <th>AudioLoudness</th>\n",
       "      <th>VocalContent</th>\n",
       "      <th>AcousticQuality</th>\n",
       "      <th>InstrumentalScore</th>\n",
       "      <th>LivePerformanceLikelihood</th>\n",
       "      <th>MoodScore</th>\n",
       "      <th>TrackDurationMs</th>\n",
       "      <th>Energy</th>\n",
       "      <th>BeatsPerMinute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.603610</td>\n",
       "      <td>-7.636942</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.051385</td>\n",
       "      <td>0.409866</td>\n",
       "      <td>290715.6450</td>\n",
       "      <td>0.826267</td>\n",
       "      <td>147.53020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.639451</td>\n",
       "      <td>-16.267598</td>\n",
       "      <td>0.071520</td>\n",
       "      <td>0.444929</td>\n",
       "      <td>0.349414</td>\n",
       "      <td>0.170522</td>\n",
       "      <td>0.651010</td>\n",
       "      <td>164519.5174</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>136.15963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.514538</td>\n",
       "      <td>-15.953575</td>\n",
       "      <td>0.110715</td>\n",
       "      <td>0.173699</td>\n",
       "      <td>0.453814</td>\n",
       "      <td>0.029576</td>\n",
       "      <td>0.423865</td>\n",
       "      <td>174495.5667</td>\n",
       "      <td>0.624667</td>\n",
       "      <td>55.31989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  RhythmScore  AudioLoudness  VocalContent  AcousticQuality  \\\n",
       "0   0     0.603610      -7.636942      0.023500         0.000005   \n",
       "1   1     0.639451     -16.267598      0.071520         0.444929   \n",
       "2   2     0.514538     -15.953575      0.110715         0.173699   \n",
       "\n",
       "   InstrumentalScore  LivePerformanceLikelihood  MoodScore  TrackDurationMs  \\\n",
       "0           0.000001                   0.051385   0.409866      290715.6450   \n",
       "1           0.349414                   0.170522   0.651010      164519.5174   \n",
       "2           0.453814                   0.029576   0.423865      174495.5667   \n",
       "\n",
       "     Energy  BeatsPerMinute  \n",
       "0  0.826267       147.53020  \n",
       "1  0.145400       136.15963  \n",
       "2  0.624667        55.31989  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(DATA_PATH + \"train.csv\")\n",
    "print(df_train.shape)\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5c310cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174722, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>RhythmScore</th>\n",
       "      <th>AudioLoudness</th>\n",
       "      <th>VocalContent</th>\n",
       "      <th>AcousticQuality</th>\n",
       "      <th>InstrumentalScore</th>\n",
       "      <th>LivePerformanceLikelihood</th>\n",
       "      <th>MoodScore</th>\n",
       "      <th>TrackDurationMs</th>\n",
       "      <th>Energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>524164</td>\n",
       "      <td>0.410013</td>\n",
       "      <td>-16.794967</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.232910</td>\n",
       "      <td>0.012689</td>\n",
       "      <td>0.271585</td>\n",
       "      <td>0.664321</td>\n",
       "      <td>302901.5498</td>\n",
       "      <td>0.424867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>524165</td>\n",
       "      <td>0.463071</td>\n",
       "      <td>-1.357000</td>\n",
       "      <td>0.141818</td>\n",
       "      <td>0.057725</td>\n",
       "      <td>0.257942</td>\n",
       "      <td>0.097624</td>\n",
       "      <td>0.829552</td>\n",
       "      <td>221995.6643</td>\n",
       "      <td>0.846000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>524166</td>\n",
       "      <td>0.686569</td>\n",
       "      <td>-3.368928</td>\n",
       "      <td>0.167851</td>\n",
       "      <td>0.287823</td>\n",
       "      <td>0.210915</td>\n",
       "      <td>0.325909</td>\n",
       "      <td>0.304978</td>\n",
       "      <td>357724.0127</td>\n",
       "      <td>0.134067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  RhythmScore  AudioLoudness  VocalContent  AcousticQuality  \\\n",
       "0  524164     0.410013     -16.794967      0.023500         0.232910   \n",
       "1  524165     0.463071      -1.357000      0.141818         0.057725   \n",
       "2  524166     0.686569      -3.368928      0.167851         0.287823   \n",
       "\n",
       "   InstrumentalScore  LivePerformanceLikelihood  MoodScore  TrackDurationMs  \\\n",
       "0           0.012689                   0.271585   0.664321      302901.5498   \n",
       "1           0.257942                   0.097624   0.829552      221995.6643   \n",
       "2           0.210915                   0.325909   0.304978      357724.0127   \n",
       "\n",
       "     Energy  \n",
       "0  0.424867  \n",
       "1  0.846000  \n",
       "2  0.134067  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(DATA_PATH + \"test.csv\")\n",
    "print(df_test.shape)\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f12c623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (524164, 9)\n",
      "y_train shape : (524164,)\n",
      "X_test shape : (174722, 9)\n"
     ]
    }
   ],
   "source": [
    "target_col = \"BeatsPerMinute\"\n",
    "feature_cols = [f for f in df_train.columns if f not in ('id', target_col)]\n",
    "\n",
    "X_train = df_train[feature_cols].copy().reset_index(drop=True)\n",
    "y_train = df_train[target_col].copy().reset_index(drop=True)\n",
    "\n",
    "print(f\"X_train shape : {X_train.shape}\")\n",
    "print(f\"y_train shape : {y_train.shape}\")\n",
    "\n",
    "X_test = df_test[feature_cols].copy().reset_index(drop=True)\n",
    "\n",
    "print(f\"X_test shape : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177daff5",
   "metadata": {},
   "source": [
    "### Extracting current best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eedaba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {}\n",
    "\n",
    "for m in BEST_MODELS_LIST:\n",
    "    blueprint = joblib.load(os.path.join(BLUEPRINT_PATH, f\"{m}.joblib\"))\n",
    "    trained = joblib.load(os.path.join(MODEL_PATH, f\"{m}_trained.joblib\"))\n",
    "\n",
    "    models_dict[m] = {}\n",
    "    models_dict[m][\"blueprint\"] = blueprint\n",
    "    models_dict[m][\"trained\"] = trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08def2a",
   "metadata": {},
   "source": [
    "### Checking original individual model performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d79136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.063098\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 118.990123\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.025145\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.061888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419332, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.034243\n"
     ]
    }
   ],
   "source": [
    "for m in BEST_MODELS_LIST:\n",
    "    cv_rmse = cross_val_score(\n",
    "        models_dict[m][\"blueprint\"],\n",
    "        # models_dict[m][\"trained\"],\n",
    "        X_train,\n",
    "        y_train,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        cv=5,\n",
    "    ).mean()\n",
    "    cv_rmse = (-cv_rmse)**0.5\n",
    "    models_dict[m][\"cv_rmse\"] = cv_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "056531ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>cv_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>robust_lgbm_adil_params</td>\n",
       "      <td>26.461618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outlier_bayesian_alpha_1_1e_06_alpha_2_0_01_la...</td>\n",
       "      <td>26.466404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outlier_pca_xgb_lr_0_01_max_depth_3_n_estimato...</td>\n",
       "      <td>26.467218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outlier_lasso_alpha_0_1_max_iter_1000</td>\n",
       "      <td>26.467444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>outlier_elastic_net_alpha_1_0_l1_ratio_0_1</td>\n",
       "      <td>26.467444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_name    cv_rmse\n",
       "0                            robust_lgbm_adil_params  26.461618\n",
       "1  outlier_bayesian_alpha_1_1e_06_alpha_2_0_01_la...  26.466404\n",
       "4  outlier_pca_xgb_lr_0_01_max_depth_3_n_estimato...  26.467218\n",
       "2              outlier_lasso_alpha_0_1_max_iter_1000  26.467444\n",
       "3         outlier_elastic_net_alpha_1_0_l1_ratio_0_1  26.467444"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = models_dict.keys()\n",
    "values = [models_dict[k]['cv_rmse'] for k in models_dict.keys()]\n",
    "df_cv_rmse = pd.DataFrame(zip(index, values), columns=['model_name', 'cv_rmse'])\n",
    "df_cv_rmse.sort_values('cv_rmse', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1733c31f",
   "metadata": {},
   "source": [
    "### Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "583e0d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, models, weights=None):\n",
    "        self.models = models\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(m).fit(X.copy(), y.copy()) for m in self.models]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = np.column_stack([m.predict(X.copy()) for m in self.models_])\n",
    "        if self.weights is not None:\n",
    "            return np.average(preds, axis=1, weights=self.weights)\n",
    "            # return np.mean([p*w for p, w in zip(preds, self.weights)])\n",
    "        return np.mean(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18243bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.063098\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 118.990123\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.025145\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.061888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419332, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.034243\n"
     ]
    }
   ],
   "source": [
    "#using simple averaging\n",
    "model = AveragingRegressor(\n",
    "    models = [models_dict[key][\"blueprint\"] for key in models_dict.keys()],\n",
    "    weights = [1/len(models_dict.keys())] * len(models_dict.keys())\n",
    ")\n",
    "\n",
    "rmse = cross_val_score(\n",
    "    model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=5,\n",
    ").mean()\n",
    "rmse = (-rmse)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fea213bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blending - Simple Averaging - CV RMSE : 26.464154367409552\n"
     ]
    }
   ],
   "source": [
    "print(f\"Blending - Simple Averaging - CV RMSE : {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b1b55d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.063098\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 118.990123\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.025145\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.061888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419332, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.034243\n"
     ]
    }
   ],
   "source": [
    "#weight based on individual cv rmse performance\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))   # stability trick\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "temp_model_list = [models_dict[key][\"blueprint\"] for key in df_cv_rmse['model_name']]\n",
    "temp_weights = softmax(df_cv_rmse['cv_rmse'] * -1)\n",
    "assert sum(temp_weights)==1\n",
    "\n",
    "model = AveragingRegressor(\n",
    "    models = temp_model_list,\n",
    "    weights = temp_weights\n",
    ")\n",
    "\n",
    "rmse = cross_val_score(\n",
    "    model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=5,\n",
    ").mean()\n",
    "rmse = (-rmse)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "427daa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blending - RMSE Softmax Weights - CV RMSE : 26.464144106038066\n"
     ]
    }
   ],
   "source": [
    "print(f\"Blending - RMSE Softmax Weights - CV RMSE : {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28abd994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>cv_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>robust_lgbm_adil_params</td>\n",
       "      <td>26.461618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outlier_bayesian_alpha_1_1e_06_alpha_2_0_01_la...</td>\n",
       "      <td>26.466404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outlier_lasso_alpha_0_1_max_iter_1000</td>\n",
       "      <td>26.467444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>outlier_elastic_net_alpha_1_0_l1_ratio_0_1</td>\n",
       "      <td>26.467444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outlier_pca_xgb_lr_0_01_max_depth_3_n_estimato...</td>\n",
       "      <td>26.467218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_name    cv_rmse\n",
       "0                            robust_lgbm_adil_params  26.461618\n",
       "1  outlier_bayesian_alpha_1_1e_06_alpha_2_0_01_la...  26.466404\n",
       "2              outlier_lasso_alpha_0_1_max_iter_1000  26.467444\n",
       "3         outlier_elastic_net_alpha_1_0_l1_ratio_0_1  26.467444\n",
       "4  outlier_pca_xgb_lr_0_01_max_depth_3_n_estimato...  26.467218"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61ba04bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.063098\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 118.990123\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.025145\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.061888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419332, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.034243\n"
     ]
    }
   ],
   "source": [
    "#custom weights based on observation\n",
    "temp_model_list = [models_dict[key][\"blueprint\"] for key in df_cv_rmse['model_name']]\n",
    "temp_weights = [0.80, 0.05, 0.05, 0.05, 0.05]\n",
    "# assert sum(temp_weights)==1\n",
    "\n",
    "model = AveragingRegressor(\n",
    "    models = temp_model_list,\n",
    "    weights = temp_weights\n",
    ")\n",
    "\n",
    "rmse = cross_val_score(\n",
    "    model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=5,\n",
    ").mean()\n",
    "rmse = (-rmse)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dc550be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blending - Custom Weights - CV RMSE : 26.461011386413695\n"
     ]
    }
   ],
   "source": [
    "print(f\"Blending - Custom Weights - CV RMSE : {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54dcb069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 524164, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.034899\n"
     ]
    }
   ],
   "source": [
    "#generate predictions for test set\n",
    "temp_model_list = [models_dict[key][\"blueprint\"] for key in df_cv_rmse['model_name']]\n",
    "temp_weights = [0.80, 0.05, 0.05, 0.05, 0.05]\n",
    "# assert sum(temp_weights)==1\n",
    "\n",
    "model = AveragingRegressor(\n",
    "    models = temp_model_list,\n",
    "    weights = temp_weights\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_test_preds = model.predict(X_test)\n",
    "\n",
    "#save predictions\n",
    "df_preds = pd.DataFrame({\n",
    "    \"id\": df_test[\"id\"],\n",
    "    target_col: y_test_preds\n",
    "})\n",
    "df_preds.to_csv(os.path.join(OUTPUT_PATH, \"preds/blending_custom_weights.csv\" ), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215e5bd5",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3e9a076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.063098\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335464, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.038252\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335465, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.027118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335465, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.091019\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335465, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.065362\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335465, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.093741\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 118.990123\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335464, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.021443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335465, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 118.952708\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335465, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 118.999800\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335465, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 118.974143\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335465, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.002522\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.025145\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335464, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.065221\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335465, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.003575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335465, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 118.992709\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335465, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.017920\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335465, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.046299\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.061888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335464, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.111150\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335465, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.049504\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335465, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.003763\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335465, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.052795\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335465, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.092228\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419332, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.034243\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335465, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.076593\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335465, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.014976\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335466, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 118.969044\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335466, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.055816\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 335466, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.054784\n"
     ]
    }
   ],
   "source": [
    "keys = models_dict.keys()\n",
    "blueprints = [models_dict[k]['blueprint'] for k in keys]\n",
    "estimators = [(k, b) for k, b in zip(keys, blueprints)]\n",
    "\n",
    "stacking = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=Ridge(),   # meta-model (can be anything)\n",
    "    cv=5                       # internal CV for meta-features\n",
    ")\n",
    "\n",
    "cv_rmse = cross_val_score(\n",
    "    stacking,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=5,\n",
    ").mean()\n",
    "cv_rmse = (-cv_rmse)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3452bacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Regressor - CV RMSE : 26.461057892697767\n"
     ]
    }
   ],
   "source": [
    "print(f\"Stacking Regressor - CV RMSE : {cv_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a06f3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 524164, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.034899\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.063098\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 118.990123\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.025145\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419331, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.061888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 419332, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 119.034243\n"
     ]
    }
   ],
   "source": [
    "#generate predictions for test set\n",
    "stacking.fit(X_train, y_train)\n",
    "y_test_preds = stacking.predict(X_test)\n",
    "\n",
    "#save predictions\n",
    "df_preds = pd.DataFrame({\n",
    "    \"id\": df_test[\"id\"],\n",
    "    target_col: y_test_preds\n",
    "})\n",
    "df_preds.to_csv(os.path.join(OUTPUT_PATH, \"preds/stacking.csv\" ), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d98ef99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-playground-series-s5e9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
