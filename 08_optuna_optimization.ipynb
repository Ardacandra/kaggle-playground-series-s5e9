{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2934dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ardacandra/miniconda3/envs/kaggle-playground-series-s5e9/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, KBinsDiscretizer, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, ClassifierMixin, clone\n",
    "import os\n",
    "import joblib\n",
    "import itertools\n",
    "import logging\n",
    "import optuna\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from src.feature_engineering import *\n",
    "from src.modeling import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbff9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "DATA_PATH = \"data/\"\n",
    "OUTPUT_PATH = \"output/\"\n",
    "BLUEPRINT_PATH = \"output/blueprint/\"\n",
    "MODEL_PATH = \"models/\"\n",
    "\n",
    "PREPROCESSING_LIST = {\n",
    "    'outlier_removal' : {\n",
    "        'enabled' : True\n",
    "    },\n",
    "    'robust_scaler'  : {\n",
    "        'enabled' : True\n",
    "    },\n",
    "    'polynomial' : {\n",
    "        'enabled' : True\n",
    "    },\n",
    "    'binning' : {\n",
    "        'enabled' : True\n",
    "    },\n",
    "    'pca' : {\n",
    "        'enabled' : True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bcea78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup logging ---\n",
    "logging.basicConfig(\n",
    "    filename=os.path.join(OUTPUT_PATH, \"08_optuna_optimization.log\"),\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logging.info(f\"starting optuna optimization...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25fc3f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"reading train and test data...\")\n",
    "\n",
    "df_train = pd.read_csv(DATA_PATH + \"train.csv\")\n",
    "# df_train = df_train.sample(n=10000).reset_index(drop=True)\n",
    "\n",
    "df_test = pd.read_csv(DATA_PATH + \"test.csv\")\n",
    "\n",
    "target_col = \"BeatsPerMinute\"\n",
    "feature_cols = [f for f in df_train.columns if f not in ('id', target_col)]\n",
    "\n",
    "X_train = df_train[feature_cols].copy().reset_index(drop=True)\n",
    "y_train = df_train[target_col].copy().reset_index(drop=True)\n",
    "\n",
    "logging.info(f\"X_train shape : {X_train.shape}\")\n",
    "logging.info(f\"y_train shape : {y_train.shape}\")\n",
    "\n",
    "X_test = df_test[feature_cols].copy().reset_index(drop=True)\n",
    "\n",
    "logging.info(f\"X_test shape : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd4a7265",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"defining preprocessing combinations...\")\n",
    "\n",
    "available_steps = []\n",
    "\n",
    "if PREPROCESSING_LIST[\"outlier_removal\"][\"enabled\"]:\n",
    "    available_steps.append((\"outlier_removal\", OutlierRemoval()))\n",
    "\n",
    "if PREPROCESSING_LIST[\"robust_scaler\"][\"enabled\"]:\n",
    "    available_steps.append((\"robust_scaler\", RobustScaler()))\n",
    "\n",
    "if PREPROCESSING_LIST[\"polynomial\"][\"enabled\"]:\n",
    "    available_steps.append((\"polynomial\", PolynomialFeatures(interaction_only=False, include_bias=False, degree=2)))\n",
    "\n",
    "if PREPROCESSING_LIST[\"binning\"][\"enabled\"]:\n",
    "    available_steps.append((\"binning\", KBinsDiscretizer(encode=\"ordinal\")))\n",
    "\n",
    "# if PREPROCESSING_LIST[\"standardization\"][\"enabled\"]:\n",
    "#     available_steps.append((\"standardization\", StandardScaler()) \n",
    "\n",
    "if PREPROCESSING_LIST[\"pca\"][\"enabled\"]:\n",
    "    available_steps.append((\"pca\", PCA(n_components=0.85)))\n",
    "\n",
    "def generate_all_combinations(steps):\n",
    "    for r in range(1, len(steps) + 1):\n",
    "        for combo in itertools.combinations(steps, r):\n",
    "            yield combo\n",
    "\n",
    "preprocessing_combinations = list(generate_all_combinations(available_steps))\n",
    "\n",
    "logging.info(f\"preprocessing combination count : {len(preprocessing_combinations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00c32c3",
   "metadata": {},
   "source": [
    "BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45feead",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"starting BayesianRidge optuna optimization...\")\n",
    "\n",
    "def objective_bay(trial, preprocessing_steps, X, y, n_splits=5):\n",
    "    # Hyperparameter suggestions\n",
    "    tol = trial.suggest_float(\"tol\", 1e-8, 1e-2, log=True)\n",
    "    alpha_1 = trial.suggest_float(\"alpha_1\", 1e-9, 1e3, log=True)\n",
    "    alpha_2 = trial.suggest_float(\"alpha_2\", 1e-9, 1e3, log=True)\n",
    "    lambda_1 = trial.suggest_float(\"lambda_1\", 1e-9, 1e3, log=True)\n",
    "    lambda_2 = trial.suggest_float(\"lambda_2\", 1e-9, 1e3, log=True)\n",
    "    fit_intercept = trial.suggest_categorical(\"fit_intercept\", [True, False])\n",
    "\n",
    "    model = Pipeline(\n",
    "        preprocessing_steps + [\n",
    "            (\"regressor\", BayesianRidge(\n",
    "                tol=tol,\n",
    "                alpha_1=alpha_1,\n",
    "                alpha_2=alpha_2,\n",
    "                lambda_1=lambda_1,\n",
    "                lambda_2=lambda_2,\n",
    "                fit_intercept=fit_intercept,\n",
    "                compute_score=False,\n",
    "                verbose=False\n",
    "            ))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "    return -scores.mean()\n",
    "\n",
    "model_name = \"bayesian_ridge\"\n",
    "results = []\n",
    "for combo in preprocessing_combinations:\n",
    "    steps = []\n",
    "    steps_name = []\n",
    "    for step_name, transformer in combo:\n",
    "        steps.append((step_name, transformer))\n",
    "        steps_name.append(step_name)\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(lambda trial:objective_bay(trial, steps, X_train, y_train), n_trials=30)\n",
    "\n",
    "    logging.info(f\"model_name: {model_name}. steps : {','.join(steps_name)}. best params: {study.best_params}. best rmse: {study.best_value}\")\n",
    "    \n",
    "    results.append({\n",
    "        'model' : model_name,\n",
    "        'steps' : ','.join(steps_name),\n",
    "        'best_params' : study.best_params,\n",
    "        'best_rmse' : study.best_value,\n",
    "    })\n",
    "\n",
    "    df_results = pd.DataFrame(results).sort_values('best_rmse', ascending=True)\n",
    "    #save temporary results to csv\n",
    "    df_results.to_csv(os.path.join(OUTPUT_PATH, f\"08_optuna_optimization_{model_name}_results.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d1252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f942676",
   "metadata": {},
   "source": [
    "LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b3464e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-playground-series-s5e9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
